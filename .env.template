# Copy this file to `.env` and fill in your actual values.
# LlumDocs loads everything via `llumdocs.llm` and FastAPI settings.

# --- OpenAI / LiteLLM configuration ---
# API key for OpenAI-compatible providers (LiteLLM will route calls).
OPENAI_API_KEY=your-openai-api-key-here

# Preferred text model id when no explicit `model_hint` is provided.
# Examples: gpt-4o-mini, gpt-4o, gpt-3.5-turbo, ollama/llama3.1:8b
LLUMDOCS_DEFAULT_MODEL=gpt-4o-mini

# Preferred vision model id for image description tasks.
# Examples: o4-mini, gpt-4.1-mini, ollama/qwen3-vl:8b
LLUMDOCS_DEFAULT_VISION_MODEL=o4-mini

# --- Ollama configuration (optional) ---
# Base URL for a local Ollama server (default http://localhost:11434).
# OLLAMA_API_BASE=http://localhost:11434

# Set to "1" to completely disable using Ollama models.
LLUMDOCS_DISABLE_OLLAMA=0

# --- FastAPI / UI wiring ---
# Comma-separated list of allowed origins for CORS.
# Example: http://localhost:3000,http://127.0.0.1:3000
LLUMDOCS_CORS_ORIGINS=http://localhost:7860

# --- Test suite helpers ---
# Comma-separated list of LiteLLM ids used in live text tests.
LLUMDOCS_LIVE_TEST_MODELS=

# Comma-separated list of LiteLLM ids used in live vision tests.
LLUMDOCS_LIVE_TEST_VISION_MODELS=
