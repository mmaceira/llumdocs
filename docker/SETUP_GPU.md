## Using LlumDocs in GPU‑enabled environments

Some organisations choose to run LlumDocs on machines that have graphics processors (GPUs) to speed up certain AI workloads.
This document explains, in high‑level terms, what that means for you.

---

### What changes for end users?

When LlumDocs runs on a server with GPU support:

- **Heavy tasks can feel faster**, especially:
  - long document processing,
  - image description,
  - and large volumes of translations or rewrites.
- You may notice:
  - **shorter waiting times** for results,
  - more **responsive behaviour** under higher load.

The way you use LlumDocs does not change:

- You still access it through the same URL or integrated tools.
- The interface and features remain the same.

---

### Who needs to think about GPU setup?

GPU setup is typically handled by:

- IT or platform teams,
- data or infrastructure engineers,
- or cloud administrators.

They decide:

- which machines have GPUs,
- how LlumDocs is deployed on those machines,
- and how capacity is shared between users and teams.

As an end user, you do not need to install drivers, change settings, or choose a specific device.

---

### When to ask about GPU support

You might want to check whether LlumDocs is using GPU‑enabled infrastructure if:

- your team runs **large volumes** of AI‑assisted tasks every day,
- you often process **long or complex documents**,
- or you notice **consistent performance issues** that affect your work.

In those cases, talk to your internal contact or platform team about:

- how LlumDocs is currently hosted,
- whether GPU resources are available,
- and whether your use case would benefit from them.

They can then decide if moving LlumDocs to a GPU‑enabled environment (or adjusting existing capacity) is appropriate.
